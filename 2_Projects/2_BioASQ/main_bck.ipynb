{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff16b14b-6d3f-41ba-8667-0f28f1e03f32",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 0. Setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad0bd5-9bb4-46e2-afd5-798e42ed8572",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a32c9cb-75ad-42c2-ab38-91dee3e3386a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import nbimporter\n",
    "import bioasq_libs\n",
    "\n",
    "# Random seeds.\n",
    "from transformers import set_seed\n",
    "import tensorflow as tf\n",
    "\n",
    "set_seed(42)              # For Hugging Face.\n",
    "tf.random.set_seed(42)    # For tf, np, and python.\n",
    "\n",
    "# Suppress warnings.\n",
    "import os\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
    "    category=UserWarning\n",
    ")\n",
    "\n",
    "# cuda device.\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Limit GPU memory usage.\n",
    "torch.cuda.set_per_process_memory_fraction(0.9, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90dfd8-01e4-43d0-a305-7be2926529af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Markdown table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8407854c-814a-461f-bfe1-eaaa0daab2e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {\n",
       "        float: left;\n",
       "        margin-right: 20px; /* Optional: Adds space between table and other content */\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {\n",
    "        float: left;\n",
    "        margin-right: 20px; /* Optional: Adds space between table and other content */\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433907f-c570-4f7d-ad62-c16caaff30f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58a7396-4661-423c-a986-d255b92ba428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad6521c685a479893f0d4ced0fd23f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d12e570d6464b9499eaea82f666b8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a959d2e8284c36a071a5d3cc079ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6484a45dc44558be90f5499ad7201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb1aacc36474336abcb59fa24557e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "train_ds, valid_ds, test_ds_list = bioasq_libs.load_datasets_all()\n",
    "test_ds_merged = concatenate_datasets(test_ds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f703a-3c5d-4549-bf14-2df140c74e41",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 2. Overview."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc1efe-5b7b-4dc4-be3f-8b0cc90c9377",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Temporary convert into df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc2f87a-76f1-4c4a-b7ef-117f5d5cc5f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f58fc-f423-4f09-b44e-5d8e027efa83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1. Features: 'question', 'snippets', 'documents'.\n",
    "  - 'question': Text, one sentence for question.\n",
    "  - 'snippets': Text, one to many sentences for short information.\n",
    "  - 'documents': URL, one to many urls for a research paper from PubMed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be283e49-b587-49c8-8ab8-9051ebd9da20",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>snippets</th>\n",
       "      <th>documents</th>\n",
       "      <th>labels</th>\n",
       "      <th>answer_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is the Wnt protein modified by notum?</td>\n",
       "      <td>Notum deacylates Wnt proteins to suppress sign...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/18505598\\nh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes, \\tNotum deacylates Wnt proteins to suppre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are Chernobyl survivors at increased risk for ...</td>\n",
       "      <td>Results: A more aggressive course of breast ca...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/29787442\\nh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes, Chernobyl survivors are at increased risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do proton pump inhibitors affect thyroxine abs...</td>\n",
       "      <td>Proton-pump inhibitors, antacids and a long li...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/15073769\\nh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Proton-pump inhibitors, antacids and a long li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is protein Fbw7 a SCF type of E3 ubiquitin lig...</td>\n",
       "      <td>FBW7 (F-box and WD repeat domain-containing 7)...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/22665065\\nh...</td>\n",
       "      <td>1</td>\n",
       "      <td>Fbxw7 (also known as Fbw7, SEL-10, hCdc4, or h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is cilengitide effective for treatment of glio...</td>\n",
       "      <td>RESULTS: fourteen randomized clinical trials w...</td>\n",
       "      <td>http://www.ncbi.nlm.nih.gov/pubmed/26918452\\nh...</td>\n",
       "      <td>0</td>\n",
       "      <td>No, cilengitide does not improve survival of g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0              Is the Wnt protein modified by notum?   \n",
       "1  Are Chernobyl survivors at increased risk for ...   \n",
       "2  Do proton pump inhibitors affect thyroxine abs...   \n",
       "3  Is protein Fbw7 a SCF type of E3 ubiquitin lig...   \n",
       "4  Is cilengitide effective for treatment of glio...   \n",
       "\n",
       "                                            snippets  \\\n",
       "0  Notum deacylates Wnt proteins to suppress sign...   \n",
       "1  Results: A more aggressive course of breast ca...   \n",
       "2  Proton-pump inhibitors, antacids and a long li...   \n",
       "3  FBW7 (F-box and WD repeat domain-containing 7)...   \n",
       "4  RESULTS: fourteen randomized clinical trials w...   \n",
       "\n",
       "                                           documents  labels  \\\n",
       "0  http://www.ncbi.nlm.nih.gov/pubmed/18505598\\nh...       1   \n",
       "1  http://www.ncbi.nlm.nih.gov/pubmed/29787442\\nh...       1   \n",
       "2  http://www.ncbi.nlm.nih.gov/pubmed/15073769\\nh...       1   \n",
       "3  http://www.ncbi.nlm.nih.gov/pubmed/22665065\\nh...       1   \n",
       "4  http://www.ncbi.nlm.nih.gov/pubmed/26918452\\nh...       0   \n",
       "\n",
       "                                        answer_ideal  \n",
       "0  Yes, \\tNotum deacylates Wnt proteins to suppre...  \n",
       "1  Yes, Chernobyl survivors are at increased risk...  \n",
       "2  Proton-pump inhibitors, antacids and a long li...  \n",
       "3  Fbxw7 (also known as Fbw7, SEL-10, hCdc4, or h...  \n",
       "4  No, cilengitide does not improve survival of g...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace6048-19d3-4f47-9d8c-a75ccdc5b904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.2. Train size = 1,085.\n",
    "- Very small train set.\n",
    "- RAG with mid~heavy LLM is expected to win.\n",
    "- Full-training is not recommended. Instead consider task-specific training like QLoRA or zero-shot learning.\n",
    "- Consider data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d77a42da-7160-4592-86a5-2a2378749389",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1085\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c00b5a-3e1c-42cc-9275-d6befb9a20bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3. Length of features.\n",
    "- `snippets`: Very long, and there are exceptionally long case.\n",
    "- `documents`: Each url has len of 43, so there would be around 15 ~ 20 URLs generally.\n",
    "> #### Caution) Some len_documents are exceptionally large, which could cause significant delay during https requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee0020c-d238-448b-b113-78725275f9f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 1 url: 43.\n"
     ]
    }
   ],
   "source": [
    "cols     = ['question', 'snippets', 'documents']\n",
    "len_cols = ['len_question', 'len_snippets', 'len_documents']\n",
    "\n",
    "train_df[len_cols] = train_df[cols].map(len)\n",
    "\n",
    "train_df[len_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b78248ad-e68e-4c59-b088-c55b34c42138",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'len_question'}>,\n",
       "        <Axes: title={'center': 'len_snippets'}>],\n",
       "       [<Axes: title={'center': 'len_documents'}>, <Axes: >]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[len_cols].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "260f6cbd-8119-4582-bfbf-47e17069072e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 1 url: 43.\n"
     ]
    }
   ],
   "source": [
    "# print len of url.\n",
    "url_sample = train_df['documents'][0].split('\\n')[0]\n",
    "print(f\"Length of 1 url: {len(url_sample)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bbccf-8a83-4aae-a1f1-2106373aa7ac",
   "metadata": {},
   "source": [
    "## 2.4. Contents.\n",
    "- Questions seem very domain-specific. We will need specialized LLMs like PubMedBERT.\n",
    "- From manual review, snippets seem to be extracted from documents, especially abstract.\n",
    "- It seems we can only access abstracts via each URL.\n",
    "- We need to check carefully if retrieval from URLs are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f3d2a8-4dcb-4fbb-95c6-c01121712d3b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**question: Is the Wnt protein modified by notum?\n",
      "\n",
      "snippets: \n",
      "Notum deacylates Wnt proteins to suppress signalling activity.\n",
      "Kinetic and mass spectrometric analyses of human proteins show that Notum is a carboxylesterase that removes an essential palmitoleate moiety from Wnt proteins and thus constitutes the first known extracellular protein deacylase.\n",
      "the Wnt inhibitor notum\n",
      "the WNT-inhibitor notum.\n",
      "\n",
      "num of documents: \n",
      "395\n",
      "\n",
      "label: 1\n",
      "\n",
      "**question: Are Chernobyl survivors at increased risk for breast cancer?\n",
      "\n",
      "snippets: \n",
      "Results: A more aggressive course of breast cancer is observed in patients exposed to radiation from the Chernobyl accident under the age of 30 years (P < .01). \n",
      "A significant excess of multiple myeloma incidence [standardized incidence rate (SIR) 1.61 %, 95% confidence interval (CI) 1.01-2.21], thyroid cancer (SIR 4.18, 95% CI 3.76-4.59), female breast cancer (SIR 1.57 CI 1.40-1.73), and all cancers combined (SIR 1.07; 95% CI 1.05-1.09) was registered. \n",
      "Possible effects for further study include increased rates of thyroid, breast, and lung cancers and multiple myeloma; reduction of radiation risks of leukemia to population levels; and increased morbidity and mortality of cleanup workers from cardio- and cerebrovascular pathology.\n",
      "Furthermore, the upward trends of increases in a variety of other tumors including breast cancer, cancers of central nervous system and renal cancer have been reported in the persons exposed to Chornobyl fallout.\n",
      "Epidemiological cohort studies found increased incidence (1990-2012 gg.) of thyroid cancer in victims of Chernobyl accident (liquidators - in 4.6 times, evacuated - in 4.0 times, residents of contaminated areas - in 1.3 times) and increased incidence of breast cancer in female workers of 1986-1987.\n",
      "Historically, data from the Chernobyl reactor accident 27 years ago demonstrated a strong correlation with thyroid cancer, but data on the radiation effects of Chernobyl on breast cancer incidence have remained inconclusive.\n",
      "Re-analyzing the data reveals that the incidence of breast cancer in Chernobyl-disaster-exposed women could be higher than previously thought. \n",
      "For breast cancer, the rates and age of onset appear to vary significantly in regions differentially affected by the Chernobyl accident. \n",
      "In contrast, millions of people were exposed to radioactive isotopes in the fallout from the Chernobyl accident, within the first 20 years there was a large increase in thyroid carcinoma incidence and a possible radiation-related increase in breast cancer, but as yet there is no general increase in malignancies. \n",
      "The study demonstrated increases in breast cancer incidence in all areas following the Chernobyl accident, reflecting improvements in cancer diagnosis and registration.\n",
      "An increase in breast cancer incidence has been reported in areas of Belarus and Ukraine contaminated by the Chernobyl accident and has become an issue of public concern.\n",
      "The study demonstrated increases in breast cancer incidence in all areas following the Chernobyl accident, reflecting improvements in cancer diagnosis and registration.\n",
      "\n",
      "num of documents: \n",
      "351\n",
      "\n",
      "label: 1\n",
      "\n",
      "**question: Do proton pump inhibitors affect thyroxine absorption?\n",
      "\n",
      "snippets: \n",
      "Proton-pump inhibitors, antacids and a long list of drugs may decrease thyroxine absorption\n",
      "Many commonly used drugs, such as bile acid sequestrants, ferrous sulphate, sucralfate, calcium carbonate, aluminium-containing antacids, phosphate binders, raloxifene and proton-pump inhibitors, have also been shown to interfere with the absorption of levothyroxine.\n",
      "Pantoprazole did not influence endocrine function in healthy male volunteers during short-term treatment.\n",
      "PPIs should be added to the list of medications affecting the level of thyroid hormone in patients with hypothyroidism treated with LT4 replacement. Patients with hypothyroidism and normal TSH values during LT4 replacement therapy may need additional thyroid function testing after treatment with PPIs and may need adjustment of their LT4 dose.\n",
      "\n",
      "num of documents: \n",
      "569\n",
      "\n",
      "label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    sample = train_df.iloc[i]\n",
    "    print(f\"**question: {sample['question']}\", end='\\n\\n')\n",
    "    print(f\"snippets: \\n{sample['snippets']}\", end='\\n\\n')\n",
    "    print(f\"num of documents: \\n{len(sample['documents'])}\", end='\\n\\n')\n",
    "    print(f\"label: {sample['labels']}\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb6007-c1b3-4da1-9883-1592432c83c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.5. Class distribution.\n",
    "- Highly uneven: 'yes' (0.74) vs 'no' (0.26).\n",
    "- This would obviously make training hard.\n",
    "- Should consider **class-balanced sampling**, **data augmentation**, **loss with class weights**, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f7f6e2b-13c3-4a7c-bcef-7d77d5c1b04a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "1    0.739171\n",
       "0    0.260829\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['labels'].value_counts() / len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42591b-683d-4fa2-b3f5-50293cc85772",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.6. Convert back to ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "364b9481-98bd-4ab5-b6c6-b74897557724",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c53d7-a54e-4c72-b10d-cbba2e4bf56f",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 3. Non-RAG.\n",
    "- No snippets or documents.\n",
    "- Let's check what pretrained non-RAG LLMs can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c52bf-b340-40c4-ac67-964e51f3de58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1. Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7183228d-7c3d-426e-8a14-2cc73b4865da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'labels'],\n",
       "    num_rows: 1085\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_query     = ['question', 'labels']\n",
    "train_ds_query = train_ds.select_columns(cols_query)\n",
    "valid_ds_query = valid_ds.select_columns(cols_query)\n",
    "\n",
    "train_ds_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db6404-5efb-4e76-9510-e4c901323897",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2. No Fine-Tuning.\n",
    "- **Accuracy**: 0.44.\n",
    "- Very low, because we should train a classification head, plus it is highly domain-specific, so the model was rarely seen these data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b9ff242-6cab-4468-b88c-d5ca4b993d9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import pipeline\n",
    "\n",
    "# Model.\n",
    "classifier      = pipeline(\"text-classification\", model=\"distilbert-base-uncased\")\n",
    "\n",
    "# Metrics.\n",
    "metric_accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Predict, on train set.\n",
    "predictions      = classifier(train_ds_query['question'])\n",
    "y_pred           = [int(pred['label'].split('_')[-1]) for pred in predictions]     # convert to label.\n",
    "\n",
    "# Compute accuracy.\n",
    "accuracy = metric_accuracy.compute(predictions = y_pred, \n",
    "                                   references  = train_ds_query['labels'])\n",
    "\n",
    "# Print.\n",
    "print(f\"Accuracy: {accuracy['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e353c07-d59d-4960-a3c9-b86f068b8afb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.3. Query-Only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8aef04-f65e-43c4-878e-0aca7b1f10e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.1. Model and Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1dd46f0b-2d73-4075-bb05-e594b6caf37a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer_query   = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model_query       = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b695322-810b-4c6d-8254-9044851dc4e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3.3.2. Tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e4a257e-4faf-4f06-83b8-b1d64d3e998e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc72cf12e984c809bb8ef8e218c0b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952f7a0ce9644d6d9d4a981c03962c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_query(x):\n",
    "    return tokenizer_query(x['question'],\n",
    "                           truncation=True,\n",
    "                           max_length=512,)\n",
    "\n",
    "train_ds_query = train_ds_query.map(tokenize_query, batched=True, remove_columns=['question'])\n",
    "valid_ds_query = valid_ds_query.map(tokenize_query, batched=True, remove_columns=['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261b649-c77a-4d51-972f-6057b3dfd53d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3.2. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af48d60e-c322-431d-ae60-c26eda21b7f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data collator, for dynamic padding.\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# TrainingArguments and Trainer.\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = \"./results\",\n",
    "    eval_strategy               = \"epoch\",\n",
    "    learning_rate               = 5e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    num_train_epochs            = 1,           # for test.\n",
    "    save_strategy               = \"epoch\",\n",
    "    logging_dir                 = \"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model             = model_query,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_ds_query,\n",
    "    eval_dataset      = valid_ds_query,\n",
    "    processing_class  = tokenizer,\n",
    "    data_collator     = data_collator,\n",
    "    compute_metrics   = bioasq_libs.compute_metrics      # Custom metrics.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5d7a513-72e0-4984-a6c7-4d7427a834f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Yes</th>\n",
       "      <th>F1 No</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.554129</td>\n",
       "      <td>0.738971</td>\n",
       "      <td>0.849894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2025.01.08.\n",
      "<Hyperparameters>\n",
      "- Model        : distilbert-base-uncased\n",
      "- Learning Rate: 5e-05\n",
      "- Batch Size   : 8\n",
      "- Epochs       : 1\n",
      "\n",
      "<Results>\n",
      "- Accuracy     : 0.739\n",
      "- F1-yes       : 0.8499\n",
      "- F1-no        : 0.0\n",
      "- Macro-F1     : 0.4249\n",
      "- Train Loss   : 0.5641\n",
      "- Validation Loss: 0.5541\n",
      "\n",
      "<Training Time>\n",
      "- Total Time   : 2.48 seconds\n",
      "- Time per Epoch: 2.48 seconds\n",
      "- Time per Step : 0.0182 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Freeze body.\n",
    "for param in model_query.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Train.\n",
    "trainer.train()\n",
    "\n",
    "# Print and log results.\n",
    "bioasq_libs.print_and_log_results(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502630e-b2e8-4319-8bda-4b52f11ff293",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3.4. Train with Class Weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed976ba0-0e8e-403d-a1e5-473eaab46c70",
   "metadata": {},
   "source": [
    "### 3.4.1. Class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2206ff8d-b5d2-41fb-953d-6ad8e7f9af34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.0035, 0.0012], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "n_classes     = 2\n",
    "class_counts  = Counter(train_ds_query[\"labels\"])\n",
    "class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
    "class_weights = torch.tensor([class_weights[i] for i in range(n_classes)], device=device)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f801b-d401-4dfd-8a5a-55a181a4f8ec",
   "metadata": {},
   "source": [
    "> #### Note) Raw Value for Class Weights.  \n",
    "> Avoid normalizing class weights to 0. Raw values typically work better with loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4bfff-a98b-486a-a16e-204b15826589",
   "metadata": {},
   "source": [
    "### 3.4.2. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b6e1936-50ac-4336-9c89-b5ee3e93f650",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Yes</th>\n",
       "      <th>F1 No</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612932</td>\n",
       "      <td>0.702206</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.647685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2025.01.08.\n",
      "<Hyperparameters>\n",
      "- Model        : distilbert-base-uncased\n",
      "- Learning Rate: 5e-05\n",
      "- Batch Size   : 8\n",
      "- Epochs       : 1\n",
      "\n",
      "<Results>\n",
      "- Accuracy     : 0.7022\n",
      "- F1-yes       : 0.7863\n",
      "- F1-no        : 0.5091\n",
      "- Macro-F1     : 0.6477\n",
      "- Train Loss   : 0.6748\n",
      "- Validation Loss: 0.6129\n",
      "\n",
      "<Training Time>\n",
      "- Total Time   : 7.38 seconds\n",
      "- Time per Epoch: 7.38 seconds\n",
      "- Time per Step : 0.0543 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reload the model.\n",
    "model_query = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "# Data collator, for dynamic padding.\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# TrainingArguments.\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = \"./results\",\n",
    "    eval_strategy               = \"epoch\",\n",
    "    learning_rate               = 5e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    num_train_epochs            = 1,           # for test.\n",
    "    save_strategy               = \"epoch\",\n",
    "    logging_dir                 = \"./logs\",\n",
    ")\n",
    "\n",
    "# Custom trainer for class weights.\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        global class_weights    # Do NOT calculate in here, it will calculate in a batch.\n",
    "        \n",
    "        labels        = inputs.get(\"labels\")\n",
    "        num_classes   = self.model.config.num_labels  # Total number of classes.\n",
    "        device        = labels.device\n",
    "\n",
    "        # Compute the loss.\n",
    "        outputs  = model(**inputs)\n",
    "        logits   = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss     = loss_fct(logits.view(-1, num_classes), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "trainer_class = WeightedTrainer(\n",
    "    model             = model_query,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_ds_query,\n",
    "    eval_dataset      = valid_ds_query,\n",
    "    processing_class  = tokenizer,\n",
    "    data_collator     = data_collator,\n",
    "    compute_metrics   = bioasq_libs.compute_metrics  # Custom metrics.\n",
    ")\n",
    "\n",
    "# Train.\n",
    "trainer_class.train(resume_from_checkpoint=None)\n",
    "\n",
    "# Print and log results.\n",
    "bioasq_libs.print_and_log_results(trainer_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838c59c-0ecd-4aa3-a808-b806b79c8f55",
   "metadata": {},
   "source": [
    "> #### Note) Override Method in Custom Trainer.\n",
    "> Methods like `def compute_loss` only applies on 1 batch.  \n",
    "> You should be very careful not to calculate what should be done outside.  \n",
    "> e.g. Calculating `class_weights` inside will prevent normal training, but **it could be hard to find this reason!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f031a-9df4-44ec-8aa0-75ffd550c5b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1. Check Class Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c364452-6d1b-49f7-b403-7a78599798f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = train_ds_query['labels']\n",
    "pd.Series(labels).value_counts() / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5970bbf-92a0-441f-955a-bc406ec09819",
   "metadata": {},
   "source": [
    "## 3.2. Custom Trainer for Class Weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a535d5-0b1c-4871-be02-e9c7764e443c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload the model.\n",
    "model_query = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = \"./results\",\n",
    "    eval_strategy               = \"epoch\",\n",
    "    learning_rate               = 5e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    num_train_epochs            = 5,\n",
    "    save_strategy               = \"epoch\",\n",
    "    logging_dir                 = \"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model             = model_query,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_ds_query,\n",
    "    eval_dataset      = valid_ds_query,\n",
    "    processing_class  = tokenizer,\n",
    "    compute_metrics   = bioasq_libs.compute_metrics      # Custom metrics.\n",
    ")\n",
    "\n",
    "# Custom trainer for class weights.\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels        = inputs.get(\"labels\")\n",
    "        num_classes   = self.model.config.num_labels  # Total number of classes.\n",
    "        device        = labels.device\n",
    "\n",
    "        # Calculate class weights directly based on label frequency in the current batch.\n",
    "        class_counts  = torch.bincount(labels, minlength=num_classes).float()\n",
    "        class_weights = torch.zeros(num_classes, device=device)\n",
    "\n",
    "        # Avoid division by zero for missing classes.\n",
    "        class_weights[class_counts > 0] = 1.0 / class_counts[class_counts > 0]\n",
    "        class_weights /= class_weights.sum()  # Normalize weights, to sum to 1.\n",
    "\n",
    "        # Compute the loss.\n",
    "        outputs  = model(**inputs)\n",
    "        logits   = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss     = loss_fct(logits.view(-1, num_classes), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "# Use WeightedTrainer.\n",
    "trainer_class = WeightedTrainer(\n",
    "    model             = model_query,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_ds_query,\n",
    "    eval_dataset      = valid_ds_query,\n",
    "    processing_class  = tokenizer,\n",
    "    compute_metrics   = bioasq_libs.compute_metrics  # Custom metrics.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57112ca1-df62-4987-94cc-10b342c3dedf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.3. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ce5cd-3e44-47ce-a18f-80a6961096e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train.\n",
    "trainer_class.train(resume_from_checkpoint=None)\n",
    "\n",
    "# Print and log results.\n",
    "bioasq_libs.print_and_log_results(trainer_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92f325-fa29-4435-9e9b-a5213bee8469",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 4. Training Optimization.\n",
    "- Before we move on to real fine-tuning with real LLMs, we should optimize the training procedure. (~~unless you have x10 4090s~~)\n",
    "- **Optuna**: Hyperparameter tuning.\n",
    "- **QLoRA**: 8-bits quantization and PEFT using LoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fce4d-7114-4b97-b5d0-1efaba408b63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 4.1. 8-bits Quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "beee8f52-780c-4f3d-bcc7-f14ce553480d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['llm_int4_threshold', 'low_cpu_mem_usage']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "skip_modules = [\"classifier\", \"pre_classifier\"]    # This modules are not quantized. Need to check with different pretrained LLMs.\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit            = True,                # Quantize into 4-bits.                  \n",
    "    llm_int4_threshold      = 6.0,                 # Layers whose norm of weights <= 6.0 are not quantized. \n",
    "    bnb_4bit_compute_dtype  = torch.float16,       \n",
    "    low_cpu_mem_usage       = True,\n",
    "    llm_int8_skip_modules   = skip_modules         # Need to check with different pretrained LLMs.\n",
    ")\n",
    "\n",
    "model_query = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels          = 2,\n",
    "    quantization_config = quantization_config,\n",
    ").to(device)\n",
    "\n",
    "model_query = prepare_model_for_kbit_training(model_query)     # prepare quantized model for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4bd375-311f-407c-a2c3-d328c78d6163",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "> #### Note) `llm_int8_skip_modules   = [\"classifier\", \"pre_classifier\"]`.\n",
    "> Without this, error will occur with LoRA.  \n",
    "> RuntimeError: only Tensors of floating point dtype can require gradients.  \n",
    "> This error is related with library versions, which could be temporary.  \n",
    "> https://github.com/huggingface/peft/issues/1720"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8bc913-3c1f-4c24-a43c-77de4f8fd52b",
   "metadata": {
    "tags": []
   },
   "source": [
    "> #### Note) `device_map` in the `model()`.\n",
    "> Do NOT set `device_map` at inside of `model()` initialization.  \n",
    "> It will cause conflicts with Optuna, because it will not be string inside of init.  \n",
    "> Instead, use `model().to(device)`.  \n",
    "> TypeError: device() received an invalid combination of arguments - got (NoneType), but expected one of:\n",
    "> \\* (torch.device device)\n",
    ">      didn't match because some of the arguments have invalid types: (NoneType)\n",
    "> \\* (str type, int index = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fda2c-c98a-4949-b074-cec08c0b353b",
   "metadata": {
    "tags": []
   },
   "source": [
    "> #### Note) Training of Quantized Model.\n",
    "> Quantized model is directly trainable, because training requires not-quantized calculations.  \n",
    "> But adapter-based PEFTs like LoRA makes it possible, cuz it adds additional layers in addition to existing layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e36e0c-f97a-4566-9a50-bb0dfbf4eea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.2. LoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe9d1d-8982-4456-9383-f887f8831ea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.1. Check model's target module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3cf19a19-f5ea-41ed-85f8-8e41eb3c9435",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: distilbert.transformer.layer.0.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.0.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.0.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.0.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.0.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.0.ffn.lin2\n",
      "Layer name: distilbert.transformer.layer.1.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.1.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.1.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.1.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.1.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.1.ffn.lin2\n",
      "Layer name: distilbert.transformer.layer.2.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.2.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.2.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.2.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.2.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.2.ffn.lin2\n",
      "Layer name: distilbert.transformer.layer.3.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.3.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.3.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.3.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.3.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.3.ffn.lin2\n",
      "Layer name: distilbert.transformer.layer.4.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.4.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.4.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.4.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.4.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.4.ffn.lin2\n",
      "Layer name: distilbert.transformer.layer.5.attention.q_lin\n",
      "Layer name: distilbert.transformer.layer.5.attention.k_lin\n",
      "Layer name: distilbert.transformer.layer.5.attention.v_lin\n",
      "Layer name: distilbert.transformer.layer.5.attention.out_lin\n",
      "Layer name: distilbert.transformer.layer.5.ffn.lin1\n",
      "Layer name: distilbert.transformer.layer.5.ffn.lin2\n",
      "Layer name: pre_classifier\n",
      "Layer name: classifier\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        print(f\"Layer name: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53215430-d209-43af-a147-21615719137f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.2. LoRA configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3efec040-faf6-422f-aa89-5a148af431fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target module Dropout(p=0.1, inplace=False) is not supported. Currently, only the following modules are supported: `torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, `transformers.pytorch_utils.Conv1D`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[0;32m      4\u001b[0m     r              \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,                     \u001b[38;5;66;03m# Rank of the low-rank decomposition.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     lora_alpha     \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,                    \u001b[38;5;66;03m# Scaling factor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     task_type      \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEQ_CLS\u001b[39m\u001b[38;5;124m\"\u001b[39m,             \u001b[38;5;66;03m# Task type = sequential clf.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     init_lora_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molora\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare model with LoRA adapters.\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model_query \u001b[38;5;241m=\u001b[39m \u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\mapping.py:222\u001b[0m, in \u001b[0;36mget_peft_model\u001b[1;34m(model, peft_config, adapter_name, mixed, autocast_adapter_dtype, revision, low_cpu_mem_usage)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[0;32m    221\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocast_adapter_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautocast_adapter_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\peft_model.py:1449\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.__init__\u001b[1;34m(self, model, peft_config, adapter_name, **kwargs)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28mself\u001b[39m, model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, peft_config: PeftConfig, adapter_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1448\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, peft_config, adapter_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1451\u001b[0m     classifier_module_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules_to_save \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\peft_model.py:176\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[1;34m(self, model, peft_config, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[0m\n\u001b[0;32m    174\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m init_empty_weights \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx():\n\u001b[1;32m--> 176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cast_adapter_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\tuners\\lora\\model.py:141\u001b[0m, in \u001b[0;36mLoraModel.__init__\u001b[1;34m(self, model, config, adapter_name, low_cpu_mem_usage)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config, adapter_name, low_cpu_mem_usage: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:184\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, model, peft_config, adapter_name, low_cpu_mem_usage)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_injection_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name], adapter_name)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config \u001b[38;5;241m!=\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mXLORA \u001b[38;5;129;01mor\u001b[39;00m peft_config[adapter_name] \u001b[38;5;241m!=\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mXLORA:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Copy the peft_config in the injected model.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpeft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\tuners\\tuners_utils.py:501\u001b[0m, in \u001b[0;36mBaseTuner.inject_adapter\u001b[1;34m(self, model, adapter_name, autocast_adapter_dtype, low_cpu_mem_usage)\u001b[0m\n\u001b[0;32m    499\u001b[0m         ctx \u001b[38;5;241m=\u001b[39m init_empty_weights \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m ctx():\n\u001b[1;32m--> 501\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_and_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargeted_module_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m uses_dummy_target_modules:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m excluded_modules \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unmatched_modules:\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;66;03m# All targeted modules were excluded\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\tuners\\lora\\model.py:235\u001b[0m, in \u001b[0;36mLoraModel._create_and_replace\u001b[1;34m(self, lora_config, adapter_name, target, target_name, parent, current_key)\u001b[0m\n\u001b[0;32m    224\u001b[0m     target\u001b[38;5;241m.\u001b[39mupdate_layer(\n\u001b[0;32m    225\u001b[0m         adapter_name,\n\u001b[0;32m    226\u001b[0m         r,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m         lora_bias\u001b[38;5;241m=\u001b[39mlora_config\u001b[38;5;241m.\u001b[39mlora_bias,\n\u001b[0;32m    233\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m     new_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_new_module(lora_config, adapter_name, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m adapter_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapters:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# adding an additional adapter: it is not automatically trainable\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         new_module\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\peft\\tuners\\lora\\model.py:360\u001b[0m, in \u001b[0;36mLoraModel._create_new_module\u001b[1;34m(lora_config, adapter_name, target, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# no module could be matched\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported. Currently, only the following modules are supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`transformers.pytorch_utils.Conv1D`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m     )\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_module\n",
      "\u001b[1;31mValueError\u001b[0m: Target module Dropout(p=0.1, inplace=False) is not supported. Currently, only the following modules are supported: `torch.nn.Linear`, `torch.nn.Embedding`, `torch.nn.Conv2d`, `torch.nn.Conv3d`, `transformers.pytorch_utils.Conv1D`."
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r              = 8,                     # Rank of the low-rank decomposition.\n",
    "    lora_alpha     = 32,                    # Scaling factor.\n",
    "    lora_dropout   = 0.1,                   # Dropout.\n",
    "    target_modules = \"all-linear\",          # Model-agnostic.\n",
    "    task_type      = \"SEQ_CLS\",             # Task type = sequential clf.\n",
    "    init_lora_weights=\"olora\")\n",
    "\n",
    "# Prepare model with LoRA adapters.\n",
    "model_query = get_peft_model(model_query, lora_config)    \n",
    "\n",
    "# I don't know why but it occurs TypeError, but it perfectly works in Optuna's objective ftn! \n",
    "# To avoid this, use LoRA first then quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddb65b-e0da-4b01-bdab-d206cbb0c162",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.3. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ddd16017-dde6-469c-af90-cff9064cb1c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      3\u001b[0m     output_dir              \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     eval_strategy           \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     optim                   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madamw_bnb_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m,             \u001b[38;5;66;03m# 8-bits Quantization of Optimizer.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Trainer.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m trainer_class \u001b[38;5;241m=\u001b[39m \u001b[43mWeightedTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_ds_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_ds_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbioasq_libs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Custom metrics.\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m trainer_class\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\transformers\\utils\\deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp_prac\\lib\\site-packages\\transformers\\trainer.py:553\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# At this stage the model is already loaded\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_peft_model(model) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_model_quantized_and_qat_trainable:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    554\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for more details\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantization_method_supports_training:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model you are trying to fine-tune is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but that quantization method do not support training. Please open an issue on GitHub: https://github.com/huggingface/transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to request the support for training support for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
     ]
    }
   ],
   "source": [
    "# Training args for 8-bits quantization, using bitsandbytes.  \n",
    "training_args = TrainingArguments(\n",
    "    output_dir              = \"./results\",\n",
    "    eval_strategy           = \"epoch\",\n",
    "    num_train_epochs        = 1,\n",
    "    save_strategy           = \"epoch\",\n",
    "    logging_dir             = \"./logs\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    learning_rate           = 5e-5,                         # Use tuned learning rate.\n",
    "    optim                   = \"adamw_bnb_8bit\",             # 8-bits Quantization of Optimizer.\n",
    ")\n",
    "\n",
    "# Trainer.\n",
    "trainer_class = WeightedTrainer(\n",
    "    model             = model_query,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_ds_query,\n",
    "    eval_dataset      = valid_ds_query,\n",
    "    processing_class  = tokenizer,\n",
    "    compute_metrics   = bioasq_libs.compute_metrics  # Custom metrics.\n",
    ")\n",
    "\n",
    "# Train.\n",
    "trainer_class.train()\n",
    "\n",
    "# Print results.\n",
    "bioasq_libs.print_and_log_results(trainer_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86510785-08c0-4721-99f8-348d3303233c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4. Hyperparameter Tuning with Optuna.\n",
    "- Just put everything so far into `def objective`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "90ff6598-7fb6-4d15-a419-ce78941aa5d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:31:39,104] A new study created in memory with name: no-name-7a076281-5ef3-436e-8dfd-8e7114aa0eec\n",
      "Unused kwargs: ['llm_int4_threshold', 'low_cpu_mem_usage']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Yes</th>\n",
       "      <th>F1 No</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680375</td>\n",
       "      <td>0.702206</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.583980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:31:50,714] Trial 0 finished with value: 0.5839800600464511 and parameters: {'learning_rate': 3.4338038088336266e-05}. Best is trial 0 with value: 0.5839800600464511.\n",
      "Unused kwargs: ['llm_int4_threshold', 'low_cpu_mem_usage']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2025.01.08.\n",
      "<Hyperparameters>\n",
      "- Model        : distilbert-base-uncased\n",
      "- Learning Rate: 3.4338038088336266e-05\n",
      "- Batch Size   : 8\n",
      "- Epochs       : 1\n",
      "\n",
      "<Results>\n",
      "- Accuracy     : 0.7022\n",
      "- F1-yes       : 0.8058\n",
      "- F1-no        : 0.3622\n",
      "- Macro-F1     : 0.584\n",
      "- Train Loss   : 0.6897\n",
      "- Validation Loss: 0.6804\n",
      "\n",
      "<Training Time>\n",
      "- Total Time   : 8.98 seconds\n",
      "- Time per Epoch: 8.98 seconds\n",
      "- Time per Step : 0.0661 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [136/136 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Yes</th>\n",
       "      <th>F1 No</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.679380</td>\n",
       "      <td>0.702206</td>\n",
       "      <td>0.799007</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.612270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-08 17:32:02,043] Trial 1 finished with value: 0.6122696795311757 and parameters: {'learning_rate': 3.4319307052935054e-05}. Best is trial 1 with value: 0.6122696795311757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2025.01.08.\n",
      "<Hyperparameters>\n",
      "- Model        : distilbert-base-uncased\n",
      "- Learning Rate: 3.4319307052935054e-05\n",
      "- Batch Size   : 8\n",
      "- Epochs       : 1\n",
      "\n",
      "<Results>\n",
      "- Accuracy     : 0.7022\n",
      "- F1-yes       : 0.799\n",
      "- F1-no        : 0.4255\n",
      "- Macro-F1     : 0.6123\n",
      "- Train Loss   : 0.6894\n",
      "- Validation Loss: 0.6794\n",
      "\n",
      "<Training Time>\n",
      "- Total Time   : 8.98 seconds\n",
      "- Time per Epoch: 8.98 seconds\n",
      "- Time per Step : 0.066 seconds\n",
      "\n",
      "<Hyperparameters>\n",
      "- Model: distilbert-base-uncased\n",
      "- learning_rate   : 3.432e-05\n",
      "\n",
      "<Results>\n",
      "- eval_loss       : 0.6794\n",
      "- eval_accuracy   : 0.7022\n",
      "- eval_f1_yes     : 0.799\n",
      "- eval_f1_no      : 0.4255\n",
      "- eval_macro_f1   : 0.6123\n",
      "- eval_samples_per_second : 456.8\n",
      "- eval_steps_per_second : 57.1\n",
      "- epoch           : 1.0\n",
      "- Training time  : 2.48\n"
     ]
    }
   ],
   "source": [
    "# Define a training loop for Optuna.\n",
    "import optuna\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Objective ftn.\n",
    "def objective(trial, model):\n",
    "    # Hyperparameters to tune.\n",
    "    hyperparams = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 3e-5, 5e-5, log=True)\n",
    "    }\n",
    "    \n",
    "    # Quantization.\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit            = True, \n",
    "        llm_int4_threshold      = 6.0,\n",
    "        bnb_4bit_compute_dtype  = torch.float16,\n",
    "        low_cpu_mem_usage       = True,\n",
    "        llm_int8_skip_modules   = [\"classifier\", \"pre_classifier\"]\n",
    "    )\n",
    "    \n",
    "    device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_query = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, \n",
    "        num_labels          = 2,\n",
    "        quantization_config = quantization_config,\n",
    "    ).to(device)\n",
    "    \n",
    "    model_query = prepare_model_for_kbit_training(model_query)\n",
    "\n",
    "    # Apply LoRA.\n",
    "    lora_config = LoraConfig(\n",
    "    r              = 8,                     # Rank of the low-rank decomposition.\n",
    "    lora_alpha     = 32,                    # Scaling factor.\n",
    "    lora_dropout   = 0.1,                   # Dropout.\n",
    "    target_modules = [\"q_lin\", \"v_lin\"],    # Specify the target modules.\n",
    "    task_type      = \"SEQ_CLS\",              # Task type = sequential clf.\n",
    "    init_lora_weights=\"olora\")\n",
    "    \n",
    "    model_query = get_peft_model(model_query, lora_config)\n",
    "    \n",
    "    # Training args for 8-bits quantization, using bitsandbytes.  \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir              = \"./results\",\n",
    "        eval_strategy           = \"epoch\",\n",
    "        num_train_epochs        = 1,\n",
    "        save_strategy           = \"epoch\",\n",
    "        logging_dir             = \"./logs\",\n",
    "        per_device_train_batch_size = 8,\n",
    "        learning_rate           = hyperparams['learning_rate'],  # Use tuned learning rate.\n",
    "        optim                   = \"adamw_bnb_8bit\",             # 8-bits Quantization of Optimizer.\n",
    "    )\n",
    "    \n",
    "    # Trainer.\n",
    "    class WeightedTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "            labels        = inputs.get(\"labels\")\n",
    "            num_classes   = self.model.config.num_labels  # Total number of classes.\n",
    "            device        = labels.device\n",
    "\n",
    "            # Calculate class weights directly based on label frequency in the current batch.\n",
    "            class_counts  = torch.bincount(labels, minlength=num_classes).float()\n",
    "            class_weights = torch.zeros(num_classes, device=device)\n",
    "\n",
    "            # Avoid division by zero for missing classes.\n",
    "            class_weights[class_counts > 0] = 1.0 / class_counts[class_counts > 0]\n",
    "            class_weights /= class_weights.sum()  # Normalize weights, to sum to 1.\n",
    "\n",
    "            # Compute the loss.\n",
    "            outputs  = model(**inputs)\n",
    "            logits   = outputs.get(\"logits\")\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            loss     = loss_fct(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    trainer_class = WeightedTrainer(\n",
    "        model             = model_query,\n",
    "        args              = training_args,\n",
    "        train_dataset     = train_ds_query,\n",
    "        eval_dataset      = valid_ds_query,\n",
    "        processing_class  = tokenizer,\n",
    "        compute_metrics   = bioasq_libs.compute_metrics  # Custom metrics.\n",
    "    )\n",
    "\n",
    "    # Train.\n",
    "    trainer_class.train()\n",
    "    \n",
    "    # Evaluate.\n",
    "    eval_results = trainer_class.evaluate()\n",
    "    \n",
    "    # Results.\n",
    "    history          = trainer.state.log_history\n",
    "    total_train_time = sum([log.get(\"train_runtime\", 0) for log in history])\n",
    "    \n",
    "    trial.set_user_attr(key=\"model_name\", value=trainer.model.name_or_path)\n",
    "    trial.set_user_attr(key=\"best_params\", value=hyperparams)\n",
    "    trial.set_user_attr(key=\"results\", value=eval_results)\n",
    "    trial.set_user_attr(key=\"training_time\", value=total_train_time)\n",
    "    \n",
    "    # Print and log trainer.\n",
    "    bioasq_libs.print_and_log_results(trainer_class)\n",
    "    \n",
    "    return eval_results[\"eval_macro_f1\"]\n",
    "\n",
    "# Create Optuna study and optimize.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, model_query), n_trials=2)\n",
    "\n",
    "# Best trial.\n",
    "bioasq_libs.print_trial(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe2e64-b9b0-466f-b6bc-3f6f1419a5b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 5. Document Retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf7878-7876-4343-aa9c-ec6e76490b4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.1. Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c349b066-4048-4664-9894-cf5a1dfb56c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_rag     = ['question', 'labels', 'snippets', 'documents']\n",
    "train_ds_rag = train_ds.select_columns(cols_rag)\n",
    "valid_ds_rag = valid_ds.select_columns(cols_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bdddb-1348-4449-ad48-f870b444f41e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.2. Document Retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcbaed-f23c-423f-ab8e-18ac2455ac11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2.1. Prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935c277-5151-401a-b2b7-700a711b4eda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_exact = \"\"\"\\\n",
    "Question: {question}\n",
    "Snippets:\n",
    "{snippets}\n",
    "Retrieved Chunks:\n",
    "{retrieved_chunks}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a9054-37bb-458c-a539-3a5395ff3c7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5.2.2. Retrieval - from each doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eccea4-7026-4033-a282-7b486bec7bb8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def retrieve_from_each_doc(query, documents, chunk_size, chunk_overlap):\n",
    "    \n",
    "    # Text splitter.\n",
    "    text_splitter = CharacterTextSplitter(separator     = \". \", \n",
    "                                          chunk_size    = chunk_size, \n",
    "                                          chunk_overlap = chunk_overlap)\n",
    "    \n",
    "    # Embedding model.\n",
    "    model_kwargs    = {'device': device}\n",
    "    model_name      = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name   = model_name,\n",
    "                                            model_kwargs = model_kwargs)\n",
    "    \n",
    "    # For each document, split, embed, and retrieve the most relevant chunk.\n",
    "    retrievals = []\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc)                    # Split the document into chunks.\n",
    "        \n",
    "        vector_store = FAISS.from_texts(chunks, embedding_model)  # FAISS vector store.\n",
    "        \n",
    "        # Similarity search.\n",
    "        result = vector_store.similarity_search(query, k=1)       # Similarity search to retrieve the top result for this document.\n",
    "        retrievals.append(result[0].page_content)                 # Store the most relevant chunk.\n",
    "        \n",
    "    return retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1214b00e-47f9-48dc-bf9e-7fb4917e63bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5.2.3. Retrieval - from all docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b352a-9961-4f01-8ecd-e386ecd60350",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def retrieve_from_docs(query, documents, top_k_retrieval, chunk_size, chunk_overlap):\n",
    "    \n",
    "    # Text splitter.\n",
    "    text_splitter = CharacterTextSplitter(separator      = \". \", \n",
    "                                          chunk_size     = chunk_size, \n",
    "                                          chunk_overlap  = chunk_overlap)\n",
    "    \n",
    "    # Embedding model.\n",
    "    model_kwargs    = {'device': device}\n",
    "    model_name      = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name    = model_name,\n",
    "                                            model_kwargs  = model_kwargs)\n",
    "    \n",
    "    # For each document, split, embed, and retrieve the most relevant chunk.\n",
    "    retrievals = []\n",
    "    chunks     = []\n",
    "    for doc in documents:\n",
    "        chunks.extend(text_splitter.split_text(doc))                     # Split the document into chunks\n",
    "        \n",
    "    vector_store = FAISS.from_texts(chunks, embedding_model)             # FAISS vector store.\n",
    "\n",
    "    result = vector_store.similarity_search(query, k=top_k_retrieval)    # Similarity search to retrieve top-k relevant documents.\n",
    "    retrievals.extend([res.page_content for res in result])              # Store relevant chunks.\n",
    "    \n",
    "    return retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0c0a8-34fc-4cca-acaf-30ec1aa2dfcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2.4. Multithread and Async.\n",
    "- 5.2.4.2. ~ 5.2.4.7. are only for reference, use 5.2.4.8. Final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a13d6-576d-408a-9e0c-41afa31fb182",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.1. Test Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd6a65-45fd-48be-aca8-f011dae42f32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test hyperparameters.\n",
    "chunk_size      = 400\n",
    "chunk_overlap   = 20\n",
    "num_samples     = 256\n",
    "batch_sizes     = [16]\n",
    "num_workerss    = [32]\n",
    "\n",
    "# Create a smaller subset for testing\n",
    "small_train_ds_rag = train_ds_rag.select(range(num_samples))  # Select the first 256 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d374f73-ed93-4a9c-93d2-11f0cf95ab8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.2. Single sample. \n",
    "- Too slow!\n",
    "- Manual search for tags will be replaced with BeautifulSoap later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386b9ce-78b3-4d55-8b6a-726ff98a8874",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "def preprocessing_rag(sample):\n",
    "    results = []\n",
    "    doc_urls  = sample['documents'].split('\\n')    # URL of each document.\n",
    "    documents = []\n",
    "\n",
    "    for url in doc_urls:\n",
    "        loader           = WebBaseLoader(url)\n",
    "        document         = loader.load()[0]\n",
    "        abstract_pattern_begin = 'AbstractPubMedPMID\\n\\n\\n        Abstract\\n        \\n      \\n\\n\\n      \\n      '\n",
    "        abstract_idx_begin     = document.page_content.find(abstract_pattern_begin) + len(abstract_pattern_begin)\n",
    "        abstract_idx_end       = document.page_content.find('\\n', abstract_idx_begin)\n",
    "\n",
    "        abstract         = document.page_content[abstract_idx_begin:abstract_idx_end]\n",
    "        documents.append(abstract)\n",
    "\n",
    "    retrieved_chunks = retrieve_from_each_doc(query     = sample[\"question\"],\n",
    "                                              documents = documents)\n",
    "\n",
    "    # Join retrieved chunks into a single string.\n",
    "    retrieved_chunks = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Use the prompt template to create the input text.\n",
    "    input_text = prompt.format(\n",
    "        question          = sample[\"question\"],\n",
    "        snippets          = sample[\"snippets\"],\n",
    "        retrieved_chunks  = retrieved_chunks\n",
    "    )\n",
    "\n",
    "    # Use the encoded label directly.\n",
    "    labels = sample[\"labels\"]\n",
    "    \n",
    "    return {'input_text': input_text, \n",
    "            'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2cf9d-cd73-4f34-b09c-f64d251b3462",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.3. Batched, Single Thread.\n",
    "- Takes almost 26 hrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e0fba-4974-4877-9c7c-e3088cbfc860",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "call_count = 0  # Initialize a global counter.\n",
    "\n",
    "def preprocessing_rag(batch):\n",
    "    global call_count\n",
    "    call_count += 1 \n",
    "    \n",
    "    # Current time.\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Get the current time.\n",
    "    print(f'{call_count}th Batch started at: {current_time}.')\n",
    "    \n",
    "    # Process each sample in the batch.\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    total_urls_in_batch = 0\n",
    "    for idx in range(len(batch[\"question\"])):\n",
    "        question  = batch['question'][idx]\n",
    "        snippets  = batch['snippets'][idx]\n",
    "        documents = batch['documents'][idx]\n",
    "        label     = batch['labels'][idx]\n",
    "        \n",
    "        # Split documents into URLs.\n",
    "        doc_urls = documents.split(\"\\n\")\n",
    "        doc_contents = []\n",
    "        \n",
    "        total_urls_in_batch += len(doc_urls)\n",
    "\n",
    "        # Process each document URL.\n",
    "        for url in doc_urls:\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)  # Timeout in seconds.\n",
    "                response.raise_for_status()               # Raise HTTPError for bad responses (4xx and 5xx).\n",
    "\n",
    "                loader   = WebBaseLoader(url)\n",
    "                document = loader.load()[0]\n",
    "                \n",
    "                abstract_pattern_begin = 'AbstractPubMedPMID\\n\\n\\n        Abstract\\n        \\n      \\n\\n\\n      \\n      '\n",
    "                abstract_idx_begin = document.page_content.find(abstract_pattern_begin)\n",
    "                \n",
    "                if abstract_idx_begin != -1:\n",
    "                    abstract_idx_begin += len(abstract_pattern_begin)\n",
    "                    abstract_idx_end = document.page_content.find('\\n', abstract_idx_begin)\n",
    "                    abstract = document.page_content[abstract_idx_begin:abstract_idx_end]\n",
    "                else:\n",
    "                    abstract = \"Abstract not found\"\n",
    "                \n",
    "                doc_contents.append(abstract)\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"Timeout occurred for URL {url}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load URL {url}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Retrieve chunks.\n",
    "        retrieved_chunks = retrieve_from_each_doc(query=question, documents=doc_contents)\n",
    "        retrieved_chunks = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "        # Format input using prompt.\n",
    "        input_text = prompt.format(\n",
    "            question=question,\n",
    "            snippets=snippets,\n",
    "            retrieved_chunks=retrieved_chunks,\n",
    "        )\n",
    "        \n",
    "        # Add processed input and label to the batch output.\n",
    "        inputs.append(input_text)\n",
    "        labels.append(label)\n",
    "        \n",
    "        print(f'question done: {question}')\n",
    "    \n",
    "    # Finish time.\n",
    "    print(f'total_urls_in_batch = {total_urls_in_batch}')\n",
    "    \n",
    "    # Return a dictionary of lists for the batch.\n",
    "    return {\"input\": inputs, \"label\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c13d8d-15fd-4180-a667-939677695fb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_count    = 0 \n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for num_workers in num_workerss:\n",
    "        train_ds_rag_prep_small = small_train_ds_rag.map(\n",
    "            preprocessing_rag,\n",
    "            desc        = f\"Preprocessing (batch_size={batch_size}, num_workers={num_workers})\",\n",
    "            batched     = True,\n",
    "            batch_size  = batch_size  \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e4ae4-398e-437f-aedb-d0c663cb98df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.4. Multithread using `ThreadPoolExecutor`.\n",
    "- Drastically decreases running time, like few hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf93b83-e358-4183-b53e-2b09e97fd14b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "import requests\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def fetch_url(url):\n",
    "    \"\"\"Fetch content from a URL with timeout handling.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)   # 10s timeout.\n",
    "        response.raise_for_status()                # Raise HTTPError for bad responses (4xx and 5xx).\n",
    "        \n",
    "        loader   = WebBaseLoader(url)\n",
    "        document = loader.load()[0]\n",
    "        \n",
    "        abstract_pattern_begin = 'AbstractPubMedPMID\\n\\n\\n        Abstract\\n        \\n      \\n\\n\\n      \\n      '\n",
    "        abstract_idx_begin = document.page_content.find(abstract_pattern_begin)\n",
    "        if abstract_idx_begin != -1:\n",
    "            abstract_idx_begin += len(abstract_pattern_begin)\n",
    "            abstract_idx_end = document.page_content.find('\\n', abstract_idx_begin)\n",
    "            \n",
    "            return document.page_content[abstract_idx_begin:abstract_idx_end]\n",
    "        else:\n",
    "            return \"Abstract not found\"\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Timeout occurred\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Failed to load URL: {str(e)}\"\n",
    "\n",
    "def process_batch_parallel(batch):\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    \n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'{call_count}th Batch started at: {current_time}.')\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx in range(len(batch[\"question\"])):\n",
    "        question = batch['question'][idx]\n",
    "        snippets = batch['snippets'][idx]\n",
    "        documents = batch['documents'][idx]\n",
    "        label = batch['labels'][idx]\n",
    "\n",
    "        doc_urls = documents.split(\"\\n\")\n",
    "        doc_contents = []\n",
    "\n",
    "        # Parallel fetching of URLs.\n",
    "        global num_workers\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            future_to_url = {executor.submit(fetch_url, url): url for url in doc_urls}\n",
    "            for future in as_completed(future_to_url):\n",
    "                doc_contents.append(future.result())\n",
    "        \n",
    "        retrieved_chunks = retrieve_from_each_doc(query=question, documents=doc_contents)\n",
    "        retrieved_chunks = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "        input_text = prompt.format(\n",
    "            question=question,\n",
    "            snippets=snippets,\n",
    "            retrieved_chunks=retrieved_chunks,\n",
    "        )\n",
    "        \n",
    "        inputs.append(input_text)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Save intermediate dataset, cuz it could take several hours.\n",
    "    batch_dataset = Dataset.from_dict({\"input\": inputs, \"label\": labels})\n",
    "    save_path = \"rag/train_ds_rag_prep\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    batch_dataset.save_to_disk(f\"{save_path}/batch_{call_count}\")\n",
    "    \n",
    "    return {\"input\": inputs, \"label\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ae42b-3abe-4177-b553-2c26812b3e42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_count    = 0  \n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for num_workers in num_workerss:\n",
    "        train_ds_rag_prep_small = small_train_ds_rag.map(\n",
    "            process_batch_parallel,\n",
    "            desc=f\"Preprocessing (batch_size={batch_size}, num_workers={num_workers})\",\n",
    "            batched=True,\n",
    "            batch_size=batch_size  # Use the current batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30b4c8-0253-42b2-81c9-3aa5319fa088",
   "metadata": {},
   "source": [
    "> #### Note) Many Requests at once.\n",
    "> Request may fail with too many requests given period, especially multithread implementation!  \n",
    "> Failed to load URL http://www.ncbi.nlm.nih.gov/pubmed/26623375: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Max retries exceeded with url: /pubmed/26623375 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000210C236C3D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1852e-dfea-4fd3-86be-4007bc9d9917",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.5. `requests.Session`.\n",
    "- Better but still slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2ed34-808e-41ea-a32d-5479635fc6ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "import requests\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def fetch_url_session(session, url):\n",
    "    \"\"\"Fetch content from a URL with timeout handling.\"\"\"\n",
    "    try:\n",
    "        with session.get(url, timeout=10) as response:\n",
    "            response.raise_for_status()\n",
    "            loader = WebBaseLoader(url)\n",
    "            document = loader.load()[0]\n",
    "            abstract_pattern_begin = 'AbstractPubMedPMID\\n\\n\\n        Abstract\\n        \\n      \\n\\n\\n      \\n      '\n",
    "            abstract_idx_begin = document.page_content.find(abstract_pattern_begin)\n",
    "            if abstract_idx_begin != -1:\n",
    "                abstract_idx_begin += len(abstract_pattern_begin)\n",
    "                abstract_idx_end = document.page_content.find('\\n', abstract_idx_begin)\n",
    "                return document.page_content[abstract_idx_begin:abstract_idx_end]\n",
    "            else:\n",
    "                return \"Abstract not found\"\n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Timeout occurred\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to load URL: {str(e)}\"\n",
    "\n",
    "def process_batch_parallel_session(batch):\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    \n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f'{call_count}th Batch started at: {current_time}.')\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx in range(len(batch[\"question\"])):\n",
    "        question = batch['question'][idx]\n",
    "        snippets = batch['snippets'][idx]\n",
    "        documents = batch['documents'][idx]\n",
    "        label = batch['labels'][idx]\n",
    "\n",
    "        doc_urls = documents.split(\"\\n\")\n",
    "        doc_contents = []\n",
    "\n",
    "        # Parallel fetching of URLs.\n",
    "        global num_workers\n",
    "        with requests.Session() as session:  # Use a session for connection pooling.\n",
    "            with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                future_to_url = {executor.submit(fetch_url_session, session, url): url for url in doc_urls}\n",
    "                for future in as_completed(future_to_url):\n",
    "                    doc_contents.append(future.result())\n",
    "        \n",
    "        # Process the retrieved content\n",
    "        retrieved_chunks = retrieve_from_docs(query            = question, \n",
    "                                              documents        = doc_contents,\n",
    "                                              top_k_retrieval  = top_k_retrieval,\n",
    "                                              chunk_size       = chunk_size,\n",
    "                                              chunk_overlap    = chunk_overlap)\n",
    "        \n",
    "        retrieved_chunks = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "        input_text = prompt.format(\n",
    "            question=question,\n",
    "            snippets=snippets,\n",
    "            retrieved_chunks=retrieved_chunks,\n",
    "        )\n",
    "        \n",
    "        inputs.append(input_text)\n",
    "        labels.append(label)\n",
    "        \n",
    "        print(f'-- {idx+1}th question done: {question}')\n",
    "    \n",
    "    # Save intermediate dataset.\n",
    "    batch_dataset = Dataset.from_dict({\"input\": inputs, \"label\": labels})\n",
    "    save_path = \"rag/train_ds_rag_prep\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    batch_dataset.save_to_disk(f\"{save_path}/batch_{call_count}\")\n",
    "    \n",
    "    return {\"input\": inputs, \"label\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860cfd9-8f53-43de-8f35-5d6a5d3cf6c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply map function with parallel processing\n",
    "call_count    = 0  # Initialize a global counter.\n",
    "for batch_size in batch_sizes:\n",
    "    for num_workers in num_workerss:\n",
    "        train_ds_rag_prep_small = small_train_ds_rag.map(\n",
    "            process_batch_parallel_session,\n",
    "            desc=f\"Preprocessing (batch_size={batch_size}, num_workers={num_workers})\",\n",
    "            batched=True,\n",
    "            batch_size=batch_size  # Use the current batch_size\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b2590-113d-4451-98a2-65ffbc2bb0da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.6. `asyncio`.\n",
    "- Asyncronized http and io.\n",
    "- Done within 60 ~ 80 mins! \n",
    "- `BeautifulSoup` to parse html efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e71a18-48a2-46aa-abc9-eac15e3bd4cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "async def fetch_url_async(session, url):\n",
    "    \"\"\"Fetch content from a URL asynchronously.\"\"\"\n",
    "    try:\n",
    "        async with session.get(url, timeout=10) as response:\n",
    "            html = await response.text()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            abstract_div = soup.find('div', class_='abstract-content selected')\n",
    "            \n",
    "            if abstract_div:\n",
    "                abstract_list = abstract_div.find_all('p')\n",
    "                \n",
    "                # if abstract is found, return with title.\n",
    "                if abstract_list:   \n",
    "                    abstract = \" \".join(p.get_text(strip=True) for p in abstract_list)\n",
    "                    return abstract\n",
    "                else:\n",
    "                    return f\"abstract not found.\"\n",
    "                \n",
    "            else:\n",
    "                return f\"abstract_div not found.\"\n",
    "            \n",
    "    except asyncio.TimeoutError:\n",
    "        return f\"Timeout occurred: {url}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Failed to load URL: {str(e)}\"\n",
    "\n",
    "async def fetch_all_urls_async(doc_urls):\n",
    "    \"\"\"Fetch all URLs concurrently using aiohttp.\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_url_async(session, url) for url in doc_urls]\n",
    "        \n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def process_batch_parallel_async(batch, call_count, top_k_retrieval, chunk_size, chunk_overlap):\n",
    "    \"\"\"Process a batch asynchronously.\"\"\"\n",
    "    start_time = time.time()\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx in range(len(batch[\"question\"])):\n",
    "        question = batch['question'][idx]\n",
    "        snippets = batch['snippets'][idx]\n",
    "        documents = batch['documents'][idx]\n",
    "        label = batch['labels'][idx]\n",
    "\n",
    "        doc_urls = documents.split(\"\\n\")\n",
    "        doc_contents = await fetch_all_urls_async(doc_urls)  # Fully async fetch.\n",
    "\n",
    "        # Process the retrieved content.\n",
    "        retrieved_chunks = retrieve_from_docs(query            = question, \n",
    "                                              documents        = doc_contents,\n",
    "                                              top_k_retrieval  = top_k_retrieval,\n",
    "                                              chunk_size       = chunk_size,\n",
    "                                              chunk_overlap    = chunk_overlap)\n",
    "        \n",
    "        # Normalize Snippets to search the matches with retrieved_chunks.\n",
    "        import string\n",
    "        \n",
    "        def normalize(text):\n",
    "            return text.strip().lower().rstrip(string.punctuation)\n",
    "        \n",
    "        snippets_set = set(normalize(sentence) \n",
    "                           for snippet in snippets.split('\\n')\n",
    "                           for sentence in snippet.split('. '))\n",
    "        \n",
    "        # Delete chunks that are already in snippets.\n",
    "        retrieved_chunks_unique = [chunk for chunk in retrieved_chunks\n",
    "                                   if normalize(chunk) not in snippets_set]\n",
    "    \n",
    "        retrieved_chunks_unique = \"\\n\".join(retrieved_chunks_unique)\n",
    "\n",
    "        input_text = prompt_exact.format(\n",
    "            question          = question,\n",
    "            snippets          = snippets,\n",
    "            retrieved_chunks  = retrieved_chunks_unique,\n",
    "        )\n",
    "\n",
    "        inputs.append(input_text)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Don't need to save, it's very fast now :)\n",
    "    '''\n",
    "    # Save intermediate dataset, for each batch.\n",
    "    batch_dataset = Dataset.from_dict({\"input\": inputs, \"label\": labels})\n",
    "    save_path = \"rag/train_ds_rag_prep\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    batch_dataset.save_to_disk(f\"{save_path}/batch_{call_count}\")\n",
    "    '''\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{call_count}th Batch completed in {elapsed_time:.2f} seconds. ({(elapsed_time / len(batch[\"question\"])):.2f}s/ examples)')\n",
    "\n",
    "    return {\"input\": inputs, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615967b2-5a09-43da-8483-6b2f964bda1f",
   "metadata": {},
   "source": [
    "> #### Note) Parse `aiohttp.ClientSession().get`.  \n",
    "> `aiohttp.ClientSession().get()` returns a raw HTML, which should be parsed by `BeautifulSoup`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf610d-0c55-4c40-a1b5-6d5240d75d8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.7. Increased `batch_size` and `num_workers`.\n",
    "- Not very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ca52-c19d-4f4c-9d21-1baed3e20384",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters.\n",
    "chunk_size      = 400\n",
    "chunk_overlap   = 20\n",
    "batch_size      = 32\n",
    "num_workers     = 128\n",
    "\n",
    "async def process_all_batches(dataset, batch_size):\n",
    "    global call_count\n",
    "    call_count = 0  # Initialize a global counter.\n",
    "    \n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i:i + batch_size]  # Extract a batch\n",
    "        call_count += 1\n",
    "        result = await process_batch_parallel(batch, call_count)  # Process each batch asynchronously\n",
    "\n",
    "        all_inputs.extend(result[\"input\"])\n",
    "        all_labels.extend(result[\"label\"])\n",
    "        \n",
    "    # Combine all processed batches into a single dataset\n",
    "    return Dataset.from_dict({\"input\": all_inputs, \"label\": all_labels})\n",
    "        \n",
    "# Run the process and set train_ds_rag_prep\n",
    "print(f\"Processing with batch_size={batch_size}, num_workers={num_workers}.\")\n",
    "print(f\"- Num of samples = {len(small_train_ds_rag)}\")\n",
    "print(f\"- Num of batches = {int(len(small_train_ds_rag) / batch_size)}\")\n",
    "\n",
    "small_train_ds_rag_prep = await process_all_batches(small_train_ds_rag, batch_size=batch_size)\n",
    "\n",
    "# Note that additional combinations also didn't show improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08f7ce-9765-4052-bf62-1ea0e903d5d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.2.4.8. Final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebd8150f-5061-4017-9d94-c3dba44fb561",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "prompt_exact = \"\"\"\\\n",
    "Question: {question}\n",
    "Snippets:\n",
    "{snippets}\n",
    "Retrieved Chunks:\n",
    "{retrieved_chunks}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_from_docs(query, documents, top_k_retrieval, chunk_size, chunk_overlap):\n",
    "    \n",
    "    # Text splitter.\n",
    "    text_splitter = CharacterTextSplitter(separator      = \". \", \n",
    "                                          chunk_size     = chunk_size, \n",
    "                                          chunk_overlap  = chunk_overlap)\n",
    "    \n",
    "    # Embedding model.\n",
    "    model_kwargs    = {'device': device}\n",
    "    model_name      = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name    = model_name,\n",
    "                                            model_kwargs  = model_kwargs)\n",
    "    \n",
    "    # For each document, split, embed, and retrieve the most relevant chunk.\n",
    "    retrievals = []\n",
    "    chunks     = []\n",
    "    for doc in documents:\n",
    "        chunks.extend(text_splitter.split_text(doc))                     # Split the document into chunks\n",
    "        \n",
    "    vector_store = FAISS.from_texts(chunks, embedding_model)             # FAISS vector store.\n",
    "\n",
    "    result = vector_store.similarity_search(query, k=top_k_retrieval)    # Similarity search to retrieve top-k relevant documents.\n",
    "    retrievals.extend([res.page_content for res in result])              # Store relevant chunks.\n",
    "    \n",
    "    return retrievals\n",
    "\n",
    "async def fetch_url_async(session, url):\n",
    "    \"\"\"Fetch content from a URL asynchronously.\"\"\"\n",
    "    try:\n",
    "        async with session.get(url, timeout=10) as response:\n",
    "            html = await response.text()\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            abstract_div = soup.find('div', class_='abstract-content selected')\n",
    "            if abstract_div:\n",
    "                abstract_list = abstract_div.find_all('p')\n",
    "                \n",
    "                # if abstract is found, return with title.\n",
    "                if abstract_list:   \n",
    "                    abstract = \" \".join(p.get_text(strip=True) for p in abstract_list)\n",
    "                    return abstract\n",
    "                else:\n",
    "                    return f\"abstract not found.\"\n",
    "                \n",
    "            else:\n",
    "                return f\"abstract_div not found.\"\n",
    "            \n",
    "    except asyncio.TimeoutError:\n",
    "        return f\"Timeout occurred: {url}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Failed to load URL: {str(e)}\"\n",
    "\n",
    "async def fetch_all_urls_async(doc_urls):\n",
    "    \"\"\"Fetch all URLs concurrently using aiohttp.\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_url_async(session, url) for url in doc_urls]\n",
    "        \n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def process_batch_parallel_async(batch, call_count, top_k_retrieval, chunk_size, chunk_overlap):\n",
    "    \"\"\"Process a batch asynchronously.\"\"\"\n",
    "    start_time   = time.time()\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx in range(len(batch[\"question\"])):\n",
    "        question = batch['question'][idx]\n",
    "        snippets = batch['snippets'][idx]\n",
    "        documents = batch['documents'][idx]\n",
    "        label = batch['labels'][idx]\n",
    "        \n",
    "        print(f'question: {question}')\n",
    "\n",
    "        doc_urls = documents.split(\"\\n\")\n",
    "        doc_contents = await fetch_all_urls_async(doc_urls)  # Fully async fetch.\n",
    "\n",
    "        # Process the retrieved content.\n",
    "        retrieved_chunks = retrieve_from_docs(query            = question, \n",
    "                                              documents        = doc_contents,\n",
    "                                              top_k_retrieval  = top_k_retrieval,\n",
    "                                              chunk_size       = chunk_size,\n",
    "                                              chunk_overlap    = chunk_overlap)\n",
    "        \n",
    "        # Normalize Snippets to search the matches with retrieved_chunks.\n",
    "        import string\n",
    "        def normalize(text):\n",
    "            return text.strip().lower().rstrip(string.punctuation)\n",
    "        \n",
    "        snippets_set = set(normalize(sentence) \n",
    "                           for snippet in snippets.split('\\n')\n",
    "                           for sentence in snippet.split('. '))\n",
    "        \n",
    "        # Delete chunks that are already in snippets.\n",
    "        retrieved_chunks_unique = [chunk for chunk in retrieved_chunks\n",
    "                                   if normalize(chunk) not in snippets_set]\n",
    "    \n",
    "        retrieved_chunks_unique = \"\\n\".join(retrieved_chunks_unique)\n",
    "\n",
    "        # Construct input_text from prompt.\n",
    "        input_text = prompt_exact.format(\n",
    "            question          = question,\n",
    "            snippets          = snippets,\n",
    "            retrieved_chunks  = retrieved_chunks_unique,\n",
    "        )\n",
    "\n",
    "        inputs.append(input_text)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Don't need to save, it's very fast now :)\n",
    "    '''\n",
    "    # Save intermediate dataset, for each batch.\n",
    "    batch_dataset = Dataset.from_dict({\"input\": inputs, \"label\": labels})\n",
    "    save_path = \"rag/train_ds_rag_prep\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    batch_dataset.save_to_disk(f\"{save_path}/batch_{call_count}\")\n",
    "    '''\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{call_count}th Batch completed in {elapsed_time:.2f} seconds. ({(elapsed_time / len(batch[\"question\"])):.2f}s/ examples)')\n",
    "\n",
    "    return {\"input\": inputs, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa82f4-8047-43df-b62b-45ad8c0e37d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.2.4.9. Retrieve and Save.\n",
    "- Note) It could take several hours depending on your Internet speed, because of WebBaseLoader (4~5 secs/question for me)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18d1cb3a-778e-4d8f-b87b-2e54dd0a60a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Starts! (2025-01-09 03:42:07)\n",
      "- Batch size         = 16\n",
      "- Num of workers     = 64\n",
      "- Num of samples     = 1085\n",
      "- Num of batches     = 67\n",
      "- Chunk size         = 200\n",
      "- Chunk overlap      = 20\n",
      "1th Batch completed in 86.52 seconds. (5.41s/ examples)\n",
      "2th Batch completed in 82.01 seconds. (5.13s/ examples)\n",
      "3th Batch completed in 86.36 seconds. (5.40s/ examples)\n",
      "4th Batch completed in 100.74 seconds. (6.30s/ examples)\n",
      "5th Batch completed in 91.16 seconds. (5.70s/ examples)\n",
      "6th Batch completed in 76.01 seconds. (4.75s/ examples)\n",
      "7th Batch completed in 30.20 seconds. (5.03s/ examples)\n",
      "Processing Finished! (2025-01-09_03-51-20)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db51a92171b9497cb9af90f09b3d4808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/102 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Suppress chunk size warning during split.\n",
    "import logging\n",
    "logging.getLogger(\"langchain_text_splitters.base\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hyperparameters.\n",
    "chunk_size      = 200\n",
    "chunk_overlap   = 20\n",
    "batch_size      = 16\n",
    "num_workers     = 64\n",
    "top_k_retrieval = 5\n",
    "\n",
    "is_test         = False   # If True, do test with small set.\n",
    "n_samples_test  = 5\n",
    "\n",
    "ds_to_retrieve  = test_ds\n",
    "\n",
    "async def process_all_batches_async(dataset, batch_size, top_k_retrieval, chunk_size, chunk_overlap):\n",
    "    call_count = 0\n",
    "    \n",
    "    all_inputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i:i + batch_size]  \n",
    "        call_count += 1\n",
    "        \n",
    "        # Use `asyncio` from test 5.\n",
    "        result = await process_batch_parallel_async(batch, \n",
    "                                                    call_count, \n",
    "                                                    top_k_retrieval, \n",
    "                                                    chunk_size, \n",
    "                                                    chunk_overlap)  \n",
    "\n",
    "        all_inputs.extend(result[\"input\"])\n",
    "        all_labels.extend(result[\"labels\"])\n",
    "        \n",
    "    # Combine all processed batches into a single dataset.\n",
    "    return Dataset.from_dict({\"input\": all_inputs, \"labels\": all_labels})\n",
    "        \n",
    "# Run the process and set train_ds_rag_prep.\n",
    "start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"Processing Starts! ({start_time})\")\n",
    "print(f\"{'- Batch size':<20} = {batch_size}\")\n",
    "print(f\"{'- Num of workers':<20} = {num_workers}\")\n",
    "print(f\"{'- Num of samples':<20} = {len(train_ds_rag)}\")\n",
    "print(f\"{'- Num of batches':<20} = {int(len(train_ds_rag) / batch_size)}\")\n",
    "print(f\"{'- Chunk size':<20} = {chunk_size}\")\n",
    "print(f\"{'- Chunk overlap':<20} = {chunk_overlap}\")\n",
    "\n",
    "async def retrieve_and_save(ds, ds_type, is_test, n_samples_test):\n",
    "    # for test.\n",
    "    if is_test:\n",
    "        ds     = ds.select(range(n_samples_test))\n",
    "\n",
    "        ds = await process_all_batches_async(ds,\n",
    "                                             batch_size=batch_size,\n",
    "                                             top_k_retrieval=top_k_retrieval,\n",
    "                                             chunk_size=chunk_size,\n",
    "                                             chunk_overlap=chunk_overlap)\n",
    "\n",
    "    # for full process.\n",
    "    else:\n",
    "        ds = await process_all_batches_async(ds,\n",
    "                                             batch_size=batch_size,\n",
    "                                             top_k_retrieval=top_k_retrieval,\n",
    "                                             chunk_size=chunk_size,\n",
    "                                             chunk_overlap=chunk_overlap)\n",
    "        \n",
    "        end_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        print(f\"Processing Finished! ({end_time})\")\n",
    "\n",
    "        # Save the final dataset\n",
    "        ds.save_to_disk(\"datasets/rag/\" + end_time + ds_type)\n",
    "\n",
    "# retrieve.\n",
    "await retrieve_and_save(ds_to_retrieve, \"/test\", is_test=False, n_samples_test=n_samples_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b45d6-64c0-46f6-9c08-ddfd21929750",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 5.2.4.10. Load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71297bf-8706-4f1c-87cc-78d073a15ba2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load.\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Edit path to your dataset.\n",
    "load_datetime          = \"final\"\n",
    "train_ds_rag_prep_load = load_from_disk(\"datasets/rag/\" + load_datetime + \"/train\")\n",
    "valid_ds_rag_prep_load = load_from_disk(\"datasets/rag/\" + load_datetime + \"/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ab47a-8ed1-4663-8696-68fffd6f4c72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data.\n",
    "data_load_time = \"final\"\n",
    "\n",
    "# Model.\n",
    "checkpoint  = 'distilbert-base-uncased'\n",
    "\n",
    "# Create Optuna study and optimize.\n",
    "n_trials = 1\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, checkpoint, data_load_time), n_trials=n_trials)\n",
    "\n",
    "# Best trial.\n",
    "#print('**Print best trial.**')\n",
    "#bioasq_libs.print_trial(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59470f5a-e137-4475-8c2a-8abdaa1e1195",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3d82f-8a47-4510-b6dc-3661d5172fe7",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 6.1. Training Loop with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c7b253-0192-4201-a5f0-b7c52403f07b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import optuna\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_from_disk, Dataset\n",
    "from datetime import datetime\n",
    "from transformers import TrainerCallback, EarlyStoppingCallback\n",
    "\n",
    "# Save time for ensemble.\n",
    "save_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "# objective for Optuna.\n",
    "def objective(trial, is_test):\n",
    "    global save_time\n",
    "    \n",
    "    # Data.\n",
    "    load_datetime = \"final\"\n",
    "    train_ds      = load_from_disk(\"datasets/rag/\" + load_datetime + \"/train\")\n",
    "    valid_ds      = load_from_disk(\"datasets/rag/\" + load_datetime + \"/valid\")\n",
    "    test_ds       = load_from_disk(\"datasets/rag/\" + load_datetime + \"/test\")\n",
    "    \n",
    "    # Split for data augmentation.\n",
    "    train_ds_rag = bioasq_libs.split_by_snippets_docs(ds=train_ds, only_no=True).shuffle()\n",
    "    valid_ds_rag = bioasq_libs.split_by_snippets_docs(ds=valid_ds, only_no=True).shuffle()\n",
    "    \n",
    "    # Hyperparameters to tune.\n",
    "    hyperparams = {\n",
    "        'n_epochs': 30,\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [8, 16]),\n",
    "        'max_length': 512,\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 2e-2, 3e-2),\n",
    "#        'stride': trial.suggest_categorical('stride', [128, 256]),\n",
    "        'warmup_ratio': trial.suggest_float('warmup_ratio', 0.08, 0.12),     # warmup_steps = total_steps * warmup_ratio.\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 5e-5, 5e-4),\n",
    "        'lora_dropout': trial.suggest_float('lora_dropout', 0.1, 0.2),\n",
    "        'class_weights_penalty': trial.suggest_float('class_weights_penalty', 1.2, 2.0),     # multiply class weights of less frequent class, i.e. 'no'.\n",
    "        'early_stopping_patience': 3,\n",
    "        'early_stopping_threshold': 1e-3,\n",
    "        'max_grad_norm': 1.0,\n",
    "#        'gradient_accumulation_steps': trial.suggest_categorical('gradient_accumulation_steps', [0, 1]),\n",
    "#        'lr_scheduler_type': trial.suggest_categorical(\n",
    "#            'lr_scheduler_type', ['linear', 'cosine', 'cosine_with_restarts']\n",
    "#        )\n",
    "    }\n",
    "    \n",
    "    # Class weights.\n",
    "    from collections import Counter\n",
    "    labels        = train_ds_rag[\"labels\"]\n",
    "    n_classes     = 2\n",
    "    class_counts  = Counter(labels)\n",
    "    class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
    "    class_weights = torch.tensor([class_weights[i] for i in range(n_classes)], device=device)\n",
    "    class_weights[0] = class_weights[0] * hyperparams['class_weights_penalty']\n",
    "#    print(f\"Class counts: {class_counts}\")\n",
    "    \n",
    "    # LLMs to test.\n",
    "    checkpoint = trial.suggest_categorical(\n",
    "        \"checkpoint\",\n",
    "        [\n",
    "#            \"bert-base-uncased\",\n",
    "#            \"distilbert-base-uncased\",\n",
    "            \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "#            \"dmis-lab/biobert-base-cased-v1.1\",\n",
    "#            \"dmis-lab/biobert-base-cased-v1.2\",\n",
    "#            \"kamalkraj/bioelectra-base-discriminator-pubmed\",\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Start time.\n",
    "    cur_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"--- Model: {checkpoint}. ---\")\n",
    "    print(f\"--- Time: {cur_time}. ---\")\n",
    "    \n",
    "    # Settings for test.\n",
    "    if is_test:\n",
    "        train_ds_rag = train_ds_rag.select(range(20))\n",
    "        valid_ds_rag = valid_ds_rag.select(range(20))\n",
    "        hyperparams['n_epochs'] = 1\n",
    "#        checkpoint = \"distilbert-base-uncased\"\n",
    "    \n",
    "    # Tokenization.\n",
    "    tokenizer_rag = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def tokenize_rag(sample):\n",
    "        return tokenizer_rag(sample['input'], \n",
    "                             truncation      = True, \n",
    "                             padding         = 'max_length',\n",
    "                             max_length      = hyperparams['max_length'],\n",
    "#                             stride          = hyperparams['stride'],\n",
    "#                             return_overflowing_tokens = True,\n",
    "                             return_tensors  ='pt'\n",
    "                            )\n",
    "    \n",
    "    train_ds_rag = train_ds_rag.map(tokenize_rag, remove_columns=['input'])\n",
    "    valid_ds_rag = valid_ds_rag.map(tokenize_rag, remove_columns=['input'])\n",
    "    \n",
    "    \n",
    "    # Custom collate function to handle the shape after stride.\n",
    "    def collate_fn(batch):\n",
    "        input_ids       = []\n",
    "        attention_masks = []\n",
    "        labels          = []\n",
    "\n",
    "        for example in batch:\n",
    "            input_ids.extend(example['input_ids'])                          # Extend all chunks.\n",
    "            attention_masks.extend(example['attention_mask'])               # Extend attention masks.\n",
    "            labels.extend([example['labels']])  # Extend labels.\n",
    "#            labels.extend([example['labels']] * len(example['input_ids']))  # Duplicate labels, for stride.\n",
    "\n",
    "        return {\n",
    "            'input_ids'      : torch.tensor(input_ids),\n",
    "            'attention_mask' : torch.tensor(attention_masks),\n",
    "            'labels'         : torch.tensor(labels),\n",
    "        }\n",
    "    \n",
    "    # Quantization.\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit            = True, \n",
    "        llm_int4_threshold      = 6.0,\n",
    "        bnb_4bit_compute_dtype  = torch.float16,\n",
    "        low_cpu_mem_usage       = True,\n",
    "        llm_int8_skip_modules   = [\"classifier\", \"pre_classifier\"]\n",
    "    )\n",
    "    \n",
    "   # Model.\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, \n",
    "        num_labels          = 2,\n",
    "        quantization_config = quantization_config,\n",
    "    ).to(device)\n",
    "    \n",
    "    model       = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    # Target modules for LoRA. Note that \"all-linears\" can occur err or unexpected result.\n",
    "    if checkpoint == \"distilbert-base-uncased\":\n",
    "        target_modules = [\"q_lin\", \"k_lin\"]\n",
    "    else:\n",
    "#         target_modules = 'all-linear'\n",
    "        target_modules = ['query', 'key']\n",
    "\n",
    "\n",
    "    # Apply LoRA.\n",
    "    lora_config = LoraConfig(\n",
    "        r              = 8,                           # Rank of the low-rank decomposition.\n",
    "        lora_alpha     = 32,                          # Scaling factor.\n",
    "        lora_dropout   = hyperparams['lora_dropout'], # Dropout.\n",
    "        target_modules = target_modules,              # Target modules.\n",
    "        task_type      = \"SEQ_CLS\",                   # Task type = sequential clf.\n",
    "        init_lora_weights=\"olora\")\n",
    "    \n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Callbacks - Early stopping callback.\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience  = hyperparams['early_stopping_patience'],    \n",
    "        early_stopping_threshold = hyperparams['early_stopping_threshold'] \n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Training args.\n",
    "    warmup_steps = (len(train_ds_rag) / hyperparams['batch_size']) * hyperparams['n_epochs'] * hyperparams['warmup_ratio']\n",
    "    warmup_steps = int(warmup_steps)\n",
    "    training_args_rag = TrainingArguments(\n",
    "        bf16                    = True,                          # Mandatory! Training time could significantly shorten. But check your GPU.\n",
    "        logging_steps           = 100,                           # Without this, training_loss might not be properly printed on progress.\n",
    "        output_dir              = \"./results\",\n",
    "        eval_strategy           = \"epoch\",\n",
    "        num_train_epochs        = hyperparams['n_epochs'],\n",
    "        save_strategy           = \"epoch\",\n",
    "        logging_dir             = \"./logs\",\n",
    "        weight_decay            = hyperparams['weight_decay'],\n",
    "#        gradient_accumulation_steps = hyperparams['gradient_accumulation_steps'],\n",
    "        load_best_model_at_end  = True,\n",
    "        warmup_steps            = warmup_steps,\n",
    "        max_grad_norm           = hyperparams['max_grad_norm'],\n",
    "        metric_for_best_model   = 'macro_f1',\n",
    "        learning_rate           = hyperparams['learning_rate'],  # Use tuned learning rate.\n",
    "#        lr_scheduler_type       = hyperparams['lr_scheduler_type'],\n",
    "        optim                   = \"adamw_bnb_8bit\",              # 8-bits Quantization for optimizer.\n",
    "        per_device_train_batch_size = hyperparams['batch_size'],\n",
    "    )\n",
    "    \n",
    "    # Trainer for class weights.\n",
    "    class WeightedTrainer(Trainer):\n",
    "        def __init__(self, *args, class_weights, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.class_weights = class_weights  # Store class_weights as an instance attribute\n",
    "\n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "            labels        = inputs.get(\"labels\")\n",
    "            num_classes   = self.model.config.num_labels  # Total number of classes.\n",
    "            device        = labels.device\n",
    "            class_weights = self.class_weights.to(device) # Do NOT calculate in here, it will calculate in a batch.\n",
    "\n",
    "            # Compute the loss.\n",
    "            outputs  = model(**inputs)\n",
    "            logits   = outputs.get(\"logits\")\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            loss     = loss_fct(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    \n",
    "    trainer_rag = WeightedTrainer(\n",
    "        model             = model,\n",
    "        args              = training_args_rag,\n",
    "        train_dataset     = train_ds_rag,\n",
    "        eval_dataset      = valid_ds_rag,\n",
    "        processing_class  = tokenizer_rag,\n",
    "        callbacks         = [early_stopping_callback], \n",
    "        data_collator     = collate_fn,                   # Custom collate function for stride.\n",
    "        class_weights     = class_weights,\n",
    "        compute_metrics   = bioasq_libs.compute_metrics,  # Custom metrics.\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Train.\n",
    "    trainer_rag.train()\n",
    "    \n",
    "    # Evaluate.\n",
    "    eval_results = trainer_rag.evaluate()\n",
    "    \n",
    "    # Results.\n",
    "    history          = trainer_rag.state.log_history\n",
    "    total_train_time = sum([log.get(\"train_runtime\", 0) for log in history])\n",
    "    \n",
    "    trial.set_user_attr(key=\"model_name\", value=trainer_rag.model.name_or_path)\n",
    "    trial.set_user_attr(key=\"best_params\", value=hyperparams)\n",
    "    trial.set_user_attr(key=\"results\", value=eval_results)\n",
    "    trial.set_user_attr(key=\"training_time\", value=total_train_time)\n",
    "    \n",
    "    # Save logits and predictions for ensemble.\n",
    "    test_ds_list = [\n",
    "        test_ds.select(range(0, 25)),\n",
    "        test_ds.select(range(25, 51)),\n",
    "        test_ds.select(range(51, 75)),\n",
    "        test_ds.select(range(75, 102))\n",
    "    ]\n",
    "    \n",
    "    valid_logits  = bioasq_libs.get_logits_for_ensemble(valid_ds, model, tokenizer_rag, hyperparams['batch_size'])\n",
    "    valid_logits  = np.array(valid_logits)\n",
    "    valid_preds   = valid_logits.argmax(axis=-1)\n",
    "    \n",
    "    save_dir_valid = f\"predictions/{save_time}/valid\"\n",
    "    os.makedirs(save_dir_valid, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    save_path_logits_valid = f\"{save_dir_valid}/trial_{trial.number}_logits.npy\"\n",
    "    save_path_preds_valid  = f\"{save_dir_valid}/trial_{trial.number}_predictions.npy\"\n",
    "\n",
    "#    print(f\"Save valid logits to {save_path_logits_valid}.\")\n",
    "    np.save(save_path_logits_valid, valid_logits)\n",
    "    np.save(save_path_preds_valid, valid_preds)\n",
    "    \n",
    "    for i in range(len(test_ds_list)):\n",
    "        test_logits = bioasq_libs.get_logits_for_ensemble(test_ds_list[i], model, tokenizer_rag, hyperparams['batch_size'])\n",
    "        test_logits = np.array(test_logits)\n",
    "        test_preds  = test_logits.argmax(axis=-1)\n",
    "\n",
    "        save_dir = f\"predictions/{save_time}/test-{i}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)  \n",
    "\n",
    "        save_path_logits = f\"{save_dir}/trial_{trial.number}_logits.npy\"\n",
    "        save_path_preds = f\"{save_dir}/trial_{trial.number}_predictions.npy\"\n",
    "\n",
    "#        print(f\"Save logits to {save_path_logits}.\")\n",
    "        np.save(save_path_logits, test_logits)\n",
    "        \n",
    "#        print(f\"Saved preds to {save_path_preds}.\")\n",
    "        np.save(save_path_preds, test_preds)\n",
    "\n",
    "    return eval_results[\"eval_macro_f1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119279a-1b13-4b18-aefa-47cc29bc9bad",
   "metadata": {},
   "source": [
    "## 6.2. Fine-Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e535a-a96b-4e68-9093-3365c64c5c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-10 08:19:32,259] A new study created in memory with name: no-name-72698ec5-22e3-421e-bbe9-1155091a33ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract. ---\n",
      "--- Time: 2025-01-10 08:19:32. ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['llm_int4_threshold', 'low_cpu_mem_usage']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "# If True, test with a small dataset.\n",
    "is_test  = False\n",
    "n_trials = 3\n",
    "\n",
    "# Data.\n",
    "data_load_time = \"final\"\n",
    "\n",
    "# Create Optuna study and optimize.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, is_test), \n",
    "               n_trials=n_trials)\n",
    "\n",
    "# Best trial.\n",
    "# print('**Print best trial.**')\n",
    "# bioasq_libs.print_trial(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f5c76-46a6-4a58-ba56-368ceb6e78e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "fig = plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a2bb6-54af-4acd-8b46-17713e92e8c4",
   "metadata": {},
   "source": [
    "## 6.3. Ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbce3b4-e74d-4623-b88c-2ff5481285f8",
   "metadata": {},
   "source": [
    "### Ensemble - as a method that takes ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041afd4c-9966-49dd-8954-e5834ddfb706",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "import bioasq_libs\n",
    "\n",
    "def test_ensemble(test_ds, top_k, trials, save_time, is_valid=False, test_split_idx=-1):\n",
    "    # test set.\n",
    "#    load_datetime     = \"final\"\n",
    "#    test_ds           = load_from_disk(\"datasets/rag/\" + load_datetime + \"/test\")\n",
    "\n",
    "    # Number of top trials to ensemble\n",
    "#    top_k = 3\n",
    "\n",
    "    # Sort trials by value (best metrics) and select top-k\n",
    "#    top_trials = sorted(study.trials, key=lambda t: t.value, reverse=True)[:top_k]\n",
    "    top_trials = sorted(trials, key=lambda t: t.value, reverse=True)[:top_k]\n",
    "\n",
    "    # Load logits for top trials\n",
    "    logits_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    for trial in top_trials:\n",
    "        # if valid dataset:\n",
    "        if is_valid:\n",
    "            logits = np.load(f\"predictions/\" + save_time + f\"/valid/trial_{trial.number}_logits.npy\")\n",
    "            preds = np.load(f\"predictions/\" + save_time + f\"/valid/trial_{trial.number}_predictions.npy\")\n",
    "        \n",
    "        # else if test dataset:\n",
    "        else:\n",
    "            logits = np.load(f\"predictions/\" + save_time + f\"/test-{test_split_idx}/trial_{trial.number}_logits.npy\")\n",
    "            preds = np.load(f\"predictions/\" + save_time + f\"/test-{test_split_idx}/trial_{trial.number}_predictions.npy\")\n",
    "            \n",
    "        logits_list.append(logits)\n",
    "        preds_list.append(preds)\n",
    "\n",
    "\n",
    "    # Soft voting.\n",
    "    # Perform ensemble (mean of logits)\n",
    "    ensemble_logits = np.mean(logits_list, axis=0)\n",
    "\n",
    "    # Convert logits to predictions (soft voting)\n",
    "    preds_soft = np.argmax(ensemble_logits, axis=1)\n",
    "\n",
    "    # Convert preds_soft_onehot to one-hot encoding.\n",
    "    preds_soft_onehot = np.zeros((len(preds_soft), 2))\n",
    "    preds_soft_onehot[np.arange(len(preds_soft)), preds_soft] = 1\n",
    "\n",
    "\n",
    "    # Hard voting.\n",
    "    preds_hard = np.stack(preds_list, axis=0)\n",
    "    preds_hard = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds_hard)\n",
    "\n",
    "    # Convert final_predictions_hard to one-hot encoding.\n",
    "    preds_hard_onehot = np.zeros((len(preds_hard), 2))\n",
    "    preds_hard_onehot[np.arange(len(preds_hard)), preds_hard] = 1\n",
    "\n",
    "    # Compute metrics.\n",
    "    test_results_soft = bioasq_libs.compute_metrics((preds_soft_onehot, test_ds['labels']))\n",
    "    test_results_hard = bioasq_libs.compute_metrics((preds_hard_onehot, test_ds['labels']))\n",
    "\n",
    "    # Print.\n",
    "    model_names = [trial.params[\"checkpoint\"] for trial in top_trials]\n",
    "\n",
    "    \"\"\"print(\"\\n- Model:\")\n",
    "    for model_name in model_names:\n",
    "        print(model_name)\n",
    "\n",
    "    print(\"\\n- Soft Voting:\")\n",
    "    for k, v in test_results_soft.items():\n",
    "        print(f\"{k:15} : {v:.4}\")\n",
    "\n",
    "    print(\"\\n- Hard Voting:\")\n",
    "    for k, v in test_results_hard.items():\n",
    "        print(f\"{k:15} : {v:.4}\")\"\"\"\n",
    "        \n",
    "    return (test_results_soft, test_results_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39e1fa3b-6c2c-41ab-800c-1e37d50671fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble test on each test split.\n",
    "test_results = []\n",
    "test_split_idx = 0\n",
    "predictions = []\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "train_ds, valid_ds, test_ds_list = bioasq_libs.load_datasets_all()\n",
    "\n",
    "test_split_idx = 0\n",
    "for test_ds in test_ds_list:\n",
    "#    print(f'# Result of test-{test_split_idx}.')\n",
    "    top_k = 1\n",
    "    trials = study.trials\n",
    "    \n",
    "    test_results.append(test_ensemble(test_ds, \n",
    "                                      top_k=top_k, \n",
    "                                      trials=trials,\n",
    "                                      save_time=save_time, \n",
    "                                      test_split_idx=test_split_idx, \n",
    "                                      is_valid=False))\n",
    "    \n",
    "    # Get merged prediction.\n",
    "    prediction = np.load(f\"predictions/\" + save_time + f\"/test-{test_split_idx}/trial_{0}_predictions.npy\")\n",
    "    predictions.extend(prediction)\n",
    "    \n",
    "    test_split_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55cacd37-f194-41c5-8d94-4171541c4d2c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'accuracy': 0.56,\n",
       "   'f1_yes': 0.717948717948718,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.358974358974359},\n",
       "  {'accuracy': 0.56,\n",
       "   'f1_yes': 0.717948717948718,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.358974358974359}),\n",
       " ({'accuracy': 0.6923076923076923,\n",
       "   'f1_yes': 0.8181818181818182,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.4090909090909091},\n",
       "  {'accuracy': 0.6923076923076923,\n",
       "   'f1_yes': 0.8181818181818182,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.4090909090909091}),\n",
       " ({'accuracy': 0.5833333333333334,\n",
       "   'f1_yes': 0.7368421052631579,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.3684210526315789},\n",
       "  {'accuracy': 0.5833333333333334,\n",
       "   'f1_yes': 0.7368421052631579,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.3684210526315789}),\n",
       " ({'accuracy': 0.7037037037037037,\n",
       "   'f1_yes': 0.8260869565217391,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.41304347826086957},\n",
       "  {'accuracy': 0.7037037037037037,\n",
       "   'f1_yes': 0.8260869565217391,\n",
       "   'f1_no': 0.0,\n",
       "   'macro_f1': 0.41304347826086957})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b258cf9-1905-4d0c-a86d-d6da5be60612",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7352941176470589,\n",
       "  'f1_yes': 0.8461538461538461,\n",
       "  'f1_no': 0.05263157894736842,\n",
       "  'macro_f1': 0.4493927125506073},\n",
       " {'accuracy': 0.7352941176470589,\n",
       "  'f1_yes': 0.8461538461538461,\n",
       "  'f1_no': 0.05263157894736842,\n",
       "  'macro_f1': 0.4493927125506073})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ensemble(valid_ds, top_k=1, trials=study.trials, save_time=save_time, is_valid=False, test_split_idx=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58818dea-5051-40e4-9bd3-7cfd8456bed7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372549019607843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_ds_merged = concatenate_datasets(test_ds_list)\n",
    "print(accuracy_score(predictions, test_ds_merged['labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30f0a45e-2d95-4c70-b733-71578ec64906",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6275\n",
      "F1-Yes: 0.7654\n",
      "F1-No: 0.0952\n",
      "F1-Macro: 0.4303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Ground truth labels and predicted labels.\n",
    "y_true = test_ds_merged['labels']\n",
    "y_pred = predictions\n",
    "\n",
    "# Compute accuracy.\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_yes = f1_score(y_true, y_pred, pos_label=1)  # Assuming 'yes' is represented by label 1.\n",
    "f1_no = f1_score(y_true, y_pred, pos_label=0)   # Assuming 'no' is represented by label 0.\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Print F1 scores.\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1-Yes: {f1_yes:.4f}\")\n",
    "print(f\"F1-No: {f1_no:.4f}\")\n",
    "print(f\"F1-Macro: {f1_macro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6173d0ff-acc4-48fc-9e99-ac40f30531c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b69c3b51-5a21-4c36-b1fe-6df3be1b99ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_decay': 0.01401735251388831,\n",
       " 'warmup_ratio': 0.11031469988343283,\n",
       " 'learning_rate': 0.00021363253222521074,\n",
       " 'lora_dropout': 0.14529965828499203,\n",
       " 'checkpoint': 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6abfcfcb-1b12-4a46-8b3f-327dc27554ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=4, state=TrialState.COMPLETE, values=[0.9292878590955945], datetime_start=datetime.datetime(2025, 1, 9, 18, 41, 51, 938422), datetime_complete=datetime.datetime(2025, 1, 9, 18, 50, 14, 370417), params={'weight_decay': 0.01401735251388831, 'warmup_ratio': 0.11031469988343283, 'learning_rate': 0.00021363253222521074, 'lora_dropout': 0.14529965828499203, 'checkpoint': 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'}, user_attrs={'model_name': 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', 'best_params': {'n_epochs': 30, 'batch_size': 16, 'max_length': 512, 'weight_decay': 0.01401735251388831, 'warmup_ratio': 0.11031469988343283, 'learning_rate': 0.00021363253222521074, 'lora_dropout': 0.14529965828499203, 'class_weights_penalty': 1.2, 'early_stopping_patience': 3, 'early_stopping_threshold': 0.001, 'max_grad_norm': 1.0}, 'results': {'eval_loss': 0.3386478126049042, 'eval_accuracy': 0.9329446064139941, 'eval_f1_yes': 0.9453681710213777, 'eval_f1_no': 0.9132075471698113, 'eval_macro_f1': 0.9292878590955945, 'eval_runtime': 2.471, 'eval_samples_per_second': 138.812, 'eval_steps_per_second': 17.402, 'epoch': 14.0}, 'training_time': 489.0503}, system_attrs={}, intermediate_values={}, distributions={'weight_decay': FloatDistribution(high=0.02, log=False, low=0.01, step=None), 'warmup_ratio': FloatDistribution(high=0.12, log=False, low=0.08, step=None), 'learning_rate': FloatDistribution(high=0.0005, log=False, low=5e-05, step=None), 'lora_dropout': FloatDistribution(high=0.2, log=False, low=0.1, step=None), 'checkpoint': CategoricalDistribution(choices=('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', 'dmis-lab/biobert-base-cased-v1.2', 'kamalkraj/bioelectra-base-discriminator-pubmed'))}, trial_id=4, value=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff3b5c-ce59-4fb8-9fbe-0329f0e042a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
